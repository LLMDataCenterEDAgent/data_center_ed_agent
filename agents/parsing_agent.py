# agents/parsing_agent.py

from openai import OpenAI
import json
from utils.json_cleaner import extract_json_like
from utils.parser_prompt import PARSING_SYSTEM_PROMPT
from state.schemas import GeneratorSpec, EDParams
from utils.demand_extractor import extract_demand_from_text
client = OpenAI()

def normalize_generator_keys(parsed_json: dict):
    """
    LLMì´ ì˜ëª»ëœ key(G1,G2 ëŒ€ì‹  generator1 ë“±)ë¥¼ ë„£ì—ˆì„ ë•Œ êµì •í•´ì£¼ëŠ” í•¨ìˆ˜
    """

    # Case 1: ì˜¬ë°”ë¥¸ êµ¬ì¡°ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if "generators" in parsed_json:
        return parsed_json

    # Case 2: G1, G2 êµ¬ì¡°ì¼ ë•Œ
    if "G1" in parsed_json and "G2" in parsed_json:
        return {
            "generators": {
                "G1": parsed_json["G1"],
                "G2": parsed_json["G2"],
            },
            "demand": parsed_json.get("demand")
        }

    # Case 3: generator1, generator2 ë“± ì—‰ëš±í•œ ì´ë¦„ì¼ ë•Œ
    possible_names = ["generator1", "generator2", "gen1", "gen2"]
    found = [k for k in parsed_json.keys() if k.lower() in possible_names]

    if len(found) >= 2:
        return {
            "generators": {
                "G1": parsed_json[found[0]],
                "G2": parsed_json[found[1]],
            },
            "demand": parsed_json.get("demand")
        }

    raise ValueError(f"Cannot normalize generator keys: {parsed_json}")


def parse_problem(text: str) -> EDParams:

    # 1) ë¨¼ì € í•œêµ­ì–´ â†’ ì˜ì–´ ë³€í™˜
    translation_resp = client.chat.completions.create(
        model="gpt-4.1",
        messages=[
            {"role": "system", "content": "Translate to English while preserving ALL numbers exactly."},
            {"role": "user", "content": text},
        ],
        temperature=0
    )
    english_text = translation_resp.choices[0].message.content

    # 2) JSON íŒŒì‹± ì‹œë„
    attempts = 0
    last_json = None

    while attempts < 3:
        attempts += 1

        parsing_resp = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": PARSING_SYSTEM_PROMPT},
                {"role": "user", "content": english_text},
            ],
            temperature=0
        )

        raw = parsing_resp.choices[0].message.content
        last_json = raw

        parsed_json = extract_json_like(raw)
        parsed_json = normalize_generator_keys(parsed_json)

        demand = parsed_json.get("demand")

        # ğŸ”¥ Case 1: demandë¥¼ LLMì´ ìˆ«ì ë¬¸ìì—´ë¡œ ë½‘ì•˜ì„ ë•Œ
        if isinstance(demand, str):
            # "500MW" â†’ 500
            num = extract_demand_from_text(demand)
            if num is not None:
                demand = num

        # ğŸ”¥ Case 2: demandê°€ Noneì´ë©´ fallbackìœ¼ë¡œ â€œë¬¸ì œ í…ìŠ¤íŠ¸ ì „ì²´â€ì—ì„œ ìˆ«ì ì¶”ì¶œ
        if demand is None:
            demand = extract_demand_from_text(text)

        # ğŸ”¥ Case 3: ê·¸ë˜ë„ None? ì˜ì–´ í…ìŠ¤íŠ¸ fallback
        if demand is None:
            demand = extract_demand_from_text(english_text)

        # ğŸ”¥ demandê°€ ìˆ«ìë¡œ ì˜ ì¡í˜”ë‹¤ë©´ OK
        if demand is not None:
            # generators ì²˜ë¦¬
            generators = {}
            for name, vals in parsed_json["generators"].items():
                generators[name] = GeneratorSpec(name=name, **vals)

            return EDParams(generators=generators, demand=demand)

        print(f"[WARN] attempt {attempts} - demand still None")

    # 3) ìµœì¢… ì‹¤íŒ¨ ì‹œ raw JSON ì¶œë ¥ í›„ ì—ëŸ¬
    print("==== RAW JSON FROM LLM ====")
    print(last_json)
    print("===========================")

    raise ValueError("Parsing failed: demand missing even after fallback.")