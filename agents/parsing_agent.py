# agents/parsing_agent.py

from openai import OpenAI
import json
from utils.json_cleaner import extract_json_like
from utils.parser_prompt import PARSING_SYSTEM_PROMPT
from state.schemas import GeneratorSpec, EDParams
from utils.demand_extractor import extract_demand_from_text

client = OpenAI()

# --- ê¸°ì¡´ í—¬í¼ í•¨ìˆ˜ë“¤ (Step 1 í…ìŠ¤íŠ¸ íŒŒì‹±ìš©) ---

def normalize_generator_keys(parsed_json: dict):
    """
    LLMì´ ì˜ëª»ëœ key(G1,G2 ëŒ€ì‹  generator1 ë“±)ë¥¼ ë„£ì—ˆì„ ë•Œ êµì •í•´ì£¼ëŠ” í•¨ìˆ˜
    """
    # Case 1: ì˜¬ë°”ë¥¸ êµ¬ì¡°ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if "generators" in parsed_json:
        return parsed_json

    # Case 2: G1, G2 êµ¬ì¡°ì¼ ë•Œ
    if "G1" in parsed_json and "G2" in parsed_json:
        return {
            "generators": {
                "G1": parsed_json["G1"],
                "G2": parsed_json["G2"],
            },
            "demand": parsed_json.get("demand")
        }

    # Case 3: generator1, generator2 ë“± ì—‰ëš±í•œ ì´ë¦„ì¼ ë•Œ
    possible_names = ["generator1", "generator2", "gen1", "gen2"]
    found = [k for k in parsed_json.keys() if k.lower() in possible_names]

    if len(found) >= 2:
        return {
            "generators": {
                "G1": parsed_json[found[0]],
                "G2": parsed_json[found[1]],
            },
            "demand": parsed_json.get("demand")
        }

    # ì •ê·œí™” ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜ (ì´í›„ ê²€ì¦ ë¡œì§ì—ì„œ ì²˜ë¦¬)
    return parsed_json


def parse_problem(text: str) -> EDParams:
    # 1) ë¨¼ì € í•œêµ­ì–´ â†’ ì˜ì–´ ë³€í™˜
    translation_resp = client.chat.completions.create(
        model="gpt-4o",  # ìµœì‹  ëª¨ë¸ ì‚¬ìš© ê¶Œì¥
        messages=[
            {"role": "system", "content": "Translate to English while preserving ALL numbers exactly."},
            {"role": "user", "content": text},
        ],
        temperature=0
    )
    english_text = translation_resp.choices[0].message.content

    # 2) JSON íŒŒì‹± ì‹œë„
    attempts = 0
    last_json = None

    while attempts < 3:
        attempts += 1

        parsing_resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": PARSING_SYSTEM_PROMPT},
                {"role": "user", "content": english_text},
            ],
            temperature=0
        )

        raw = parsing_resp.choices[0].message.content
        last_json = raw

        try:
            parsed_json = extract_json_like(raw)
            parsed_json = normalize_generator_keys(parsed_json)

            demand = parsed_json.get("demand")

            # ğŸ”¥ Case 1: demandë¥¼ LLMì´ ìˆ«ì ë¬¸ìì—´ë¡œ ë½‘ì•˜ì„ ë•Œ
            if isinstance(demand, str):
                num = extract_demand_from_text(demand)
                if num is not None:
                    demand = num

            # ğŸ”¥ Case 2: demandê°€ Noneì´ë©´ fallbackìœ¼ë¡œ â€œë¬¸ì œ í…ìŠ¤íŠ¸ ì „ì²´â€ì—ì„œ ìˆ«ì ì¶”ì¶œ
            if demand is None:
                demand = extract_demand_from_text(text)

            # ğŸ”¥ Case 3: ê·¸ë˜ë„ None? ì˜ì–´ í…ìŠ¤íŠ¸ fallback
            if demand is None:
                demand = extract_demand_from_text(english_text)

            # ğŸ”¥ demandê°€ ìˆ«ìë¡œ ì˜ ì¡í˜”ë‹¤ë©´ OK
            if demand is not None:
                # generators ì²˜ë¦¬
                generators = {}
                if "generators" in parsed_json:
                    for name, vals in parsed_json["generators"].items():
                        generators[name] = GeneratorSpec(name=name, **vals)

                    return EDParams(generators=generators, demand=demand)
        except Exception as e:
            print(f"[WARN] parsing attempt {attempts} failed: {e}")

    # 3) ìµœì¢… ì‹¤íŒ¨ ì‹œ raw JSON ì¶œë ¥ í›„ ì—ëŸ¬
    print("==== RAW JSON FROM LLM ====")
    print(last_json)
    print("===========================")

    raise ValueError("Parsing failed: demand missing even after fallback.")


# --- ë©”ì¸ Agent í´ë˜ìŠ¤ (ìˆ˜ì •ëœ ë¶€ë¶„) ---

class ParsingAgent:
    def run(self, state: dict):
        print("\n--- Parsing Agent Started ---")

        # [í•µì‹¬] ì´ë¯¸ main.pyì—ì„œ ì£¼ì…í•œ ë°ì´í„°(params)ê°€ ìˆìœ¼ë©´ LLM íŒŒì‹±ì„ ê±´ë„ˆëœ€
        # ì´ë ‡ê²Œ í•´ì•¼ Step 2(ì‹œê³„ì—´ ë°ì´í„°)ê°€ ë‚ ì•„ê°€ì§€ ì•ŠìŒ
        if state.get("params") is not None:
            print(">> Structured data detected in 'params'. Skipping LLM parsing.")
            return state

        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸(Step 1 ë°©ì‹)ë¥¼ íŒŒì‹±
        problem_text = state.get("problem_text", "")
        if not problem_text:
            print(">> No problem text provided.")
            return state

        print(f">> Parsing text with LLM: {problem_text[:50]}...")
        
        try:
            # í…ìŠ¤íŠ¸ íŒŒì‹± ê²°ê³¼(EDParams ê°ì²´)ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            ed_params = parse_problem(problem_text)
            
            # Pydantic ê°ì²´ -> Dict ë³€í™˜ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
            # ë§Œì•½ Formulation Agentê°€ ê°ì²´ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ë˜ì–´ìˆìœ¼ë©´ ì´ ë¶€ë¶„ ì¡°ì • í•„ìš”
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ dictë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            if hasattr(ed_params, "model_dump"):
                state["params"] = ed_params.model_dump()
            else:
                state["params"] = ed_params.dict()
                
            print(">> Text parsing completed.")
            
        except Exception as e:
            print(f">> Parsing Error: {e}")
            state["params"] = None

        return state